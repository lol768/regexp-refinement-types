\documentclass[a4paper,openany,12pt]{book}
\usepackage[a4paper,left=2cm,right=2cm,top=0.5cm,bottom=0.5cm,includehead,includefoot,headheight=0.1cm,heightrounded]{geometry}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage[table,xcdraw]{xcolor}
\usepackage{float}
\usepackage[pro]{fontawesome5}
\usepackage{ragged2e}
\usepackage{titlesec}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage[printwatermark]{xwatermark}
\usepackage{amssymb}
\usepackage[export]{adjustbox}
\usepackage{tocloft}
\usepackage{etoolbox}
\usepackage{algpseudocode}
\renewcommand{\contentsname}{\normalfont \sffamily \huge \textcolor{id7-aubergine}{Table of Contents}\vspace{-1.25em}}
\renewcommand{\cftsecfont}{\normalfont}
\renewcommand{\cftsecpagefont}{\normalfont}
\usetikzlibrary{automata, positioning, shapes.symbols, arrows, chains, calc}
\usepackage{shellesc}
\usepackage{minted}
\usemintedstyle{idseven}
\usepackage{listings}
\usepackage[hidelinks]{hyperref}
%\usepackage[osfigures]{opensans}
\usepackage{lastpage}
\usepackage{fancyhdr}
\usepackage{mdframed}
\usepackage{outlines}
\usepackage{bm}
\usepackage{array}
\usepackage{enumitem}
\usepackage[round]{natbib}
\usepackage{environ}
\usepackage{varwidth}
\usepackage{mathtools}
\usepackage{pagecolor}
\usepackage{wrapfig}
\usepackage{nameref}
\usepackage{fontspec}
\setsansfont{Proxima Nova}
\setmonofont{Ubuntu Mono}
\newfontfamily\warwickfont[
Scale=MatchLowercase
%  Path = fonts/
]{Avenir Next}
\makeatletter
\newcommand*{\currentname}{\@currentlabelname}
\makeatother
\usepackage{csquotes}
\usepackage{newfloat}
\usepackage{caption}
\usepackage[super]{nth}
\titleformat{\chapter}[display]
{\normalfont \sffamily \Huge  \color{id7-aubergine}}
{\vspace{-20pt} \flushright \large \color{id7-aubergine} \warwickfont \MakeUppercase { \chaptertitlename \hspace{1 ex} }  { \fontsize{60}{60}\selectfont \color{id7-aubergine} \sffamily  \thechapter }} {0 pt}{\vspace{-40pt}\Huge}
\newlength{\MyMdframedWidthTweak}%
\NewEnviron{MyMdframed}[1][]{%
    \setlength{\MyMdframedWidthTweak}{\dimexpr%
        +\mdflength{innerleftmargin}
        +\mdflength{innerrightmargin}
        +\mdflength{leftmargin}
        +\mdflength{rightmargin}
    }%
    \savebox0{%
        \begin{varwidth}{\dimexpr\linewidth-\MyMdframedWidthTweak\relax}%
            \BODY
        \end{varwidth}%
    }%
    \begin{mdframed}[
        backgroundcolor=lightgrey,
        topline=true,
        rightline=false,
        leftline=false,
        linecolor=id7-aubergine,
        userdefinedwidth=\dimexpr\wd0+\MyMdframedWidthTweak\relax, 
        #1]
        \usebox0
    \end{mdframed}
}
\titlespacing*{\chapter}
{0pt}{0pt}{2.0ex}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\title{}
\author{}
\definecolor{infogreen}{rgb}{0.153, 0.682, 0.376}
\definecolor{id7-aubergine}{HTML}{5B3069}
\definecolor{id7-gray}{HTML}{3F4246}
\definecolor{body-text}{HTML}{333333}
\definecolor{id7-gold}{HTML}{886C11}
\definecolor{id7-burnt-orange}{HTML}{A14418}
\definecolor{id7-ruby-red}{HTML}{89102C}
\definecolor{id7-emerald-green}{HTML}{797906}
\definecolor{id7-sky-blue}{HTML}{204F79}
\definecolor{id7-sky-blue-tint}{HTML}{bccad7}
\definecolor{skyblue}{rgb}{0.125, 0.31, 0.475}
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}
\definecolor{todocolor}{rgb}{0.688,0.8176,0.93137}
\newcommand{\todobox}[1] {\colorbox{todocolor}{\parbox{\dimexpr \linewidth-\columnsep}{\vspace{.75\baselineskip}\centering\parbox{0.95\linewidth}{\faIcon{lightbulb} \textbf{TODO:} #1\vspace{.75\baselineskip}}}}}
\newcommand{\readbox}[1] {\colorbox{infogreen}{\parbox{\textwidth}{\vspace{.75\baselineskip}\centering\parbox{0.95\textwidth}{\textcolor{white}{\faicon{book} \textbf{#1}\vspace{.75\baselineskip}}}}}}
\def\labelitemi{\textcolor{id7-aubergine}{\textbullet}}
\def\labelitemii{\textcolor{id7-aubergine}{\circ}}
\def\labelitemiii{\textcolor{id7-aubergine}{--}}
\definecolor{infogreenlight}{rgb}{0.75,1,0.75}

\newcommand{\infobox}[1] {\colorbox{infogreenlight}{\parbox{\textwidth}{\vspace{.75\baselineskip}\centering\parbox{0.95\textwidth}{\faicon{info-circle} #1\vspace{.75\baselineskip}}}}}

\newcommand{\boxedfigure}[2]{\begin{MyMdframed}\begin{figure}[H]
            \begin{center}\vspace{2em}\includegraphics[width=0.5\textwidth]{#1}\end{center}
            \caption{#2}
\end{figure}\end{MyMdframed}}

\newcommand{\widthboxedfigure}[3]{\begin{MyMdframed}\begin{figure}[H]
            \begin{center}\vspace{2em}\includegraphics[width=#3\textwidth]{#1}\end{center}
            \caption{#2}
\end{figure}\end{MyMdframed}}

\newcommand{\infoinlineicon}[1] {\colorbox{infogreenlight}{\faicon{info-circle} #1}}

\newcommand{\infoinline}[1] {\colorbox{infogreenlight}{#1}}

\definecolor{orange}{rgb}{0.9529,0.85176,0.5070588}

\newcommand{\warnbox}[1] {\colorbox{orange}{\parbox{\textwidth}{\vspace{.75\baselineskip}\centering\parbox{0.95\textwidth}{\faicon{exclamation-triangle} #1\vspace{.75\baselineskip}}}}}

\newcommand{\warninlineicon}[1] {\colorbox{orange}{\faicon{exclamation-triangle} #1}}

\makeatletter
\let\old@rule\@rule
\def\@rule[#1]#2#3{\textcolor{lightgrey}{\old@rule[#1]{#2}{#3}}}
\makeatother

\newcommand{\warninline}[1] {\colorbox{orange}{#1}}

\titleformat{\section}
{\normalfont\sffamily\huge\color{id7-aubergine}}
{\thesection. }{0em}{}

\titleformat{\subsection}
{\normalfont\Large\sffamily\color{id7-aubergine}}
{\thesubsection. }{0em}{}

\titleformat{\subsubsection}
{\normalfont\large\sffamily\color{id7-aubergine}}
{\thesubsubsection. }{0em}{}
\fancyhf{}
\pagestyle{fancy}

\renewcommand{\headrulewidth}{0pt}
\lfoot{\textcolor{grey}{Adam Williams}}
\rfoot{\textcolor{grey}{Page \thepage{} of \pageref{LastPage}}}

\renewcommand*\footnoterule{\noindent\makebox[\textwidth]{\includegraphics[width=\paperwidth]{divider}}}

% Redefine the plain page style
\fancypagestyle{plain}{%
	\fancyhf{}%
	\fancyhead[L]{\textcolor{grey}{\thedate}}%
	\fancyhead[R]{\textcolor{grey}{\currentname}}%
	\fancyfoot[L]{\textcolor{grey}{Adam Williams}}%
	\fancyfoot[R]{\textcolor{grey}{Page \thepage{} of \pageref{LastPage}}}%
	\renewcommand{\headrulewidth}{0pt}% Line at the header invisible
	\renewcommand{\footrulewidth}{0pt}% Line at the footer visible
}
\definecolor{grey}{rgb}{0.5,0.5,0.5}
\definecolor{lightgrey}{rgb}{0.96,0.96,0.96}

\def \spacedrule {\textcolor{id7-aubergine}{\hrule}\vspace{1em}}
\def \thedate {\today}
\lhead{\textcolor{grey}{\thedate}}
\rhead{\textcolor{grey}{\currentname}}

% Set up example boxes

\DeclareFloatingEnvironment[fileext=frm,placement={!ht},name=Example]{exampleflt}
\captionsetup[exampleflt]{labelfont=bf}

\newenvironment{example}[1]
{\begin{exampleflt}[tb]
		\begin{mdframed} \setlength{\parskip}{1em}
			\captionsetup{name=\faPuzzlePiece{} Example, singlelinecheck=false,font={color=id7-aubergine,sf},position=top}
			\vspace{0.5em}
			\caption{#1}\hfill
			\vspace{-1.8em}
			\rmfamily
			\captionsetup{style=default}

			}
			{\end{mdframed}\end{exampleflt}
}

% And algorithm boxes

\DeclareFloatingEnvironment[fileext=frm,placement={!ht},name=Algorithm]{algorithmflt}
\captionsetup[figure]{name=\faImage{} Figure, singlelinecheck=false,font={color=id7-aubergine,sf},position=top,labelfont=bf}

\newenvironment{algbox}[1]
{\begin{algorithmflt}[tb]
		\begin{mdframed} \setlength{\parskip}{1em}
			\captionsetup{name=\faCogs{} Algorithm, singlelinecheck=false,font={color=id7-aubergine,sf},position=top}
			\vspace{0.5em}
			\caption{#1}\hfill
			\vspace{-1.8em}

			\rmfamily
			\captionsetup{style=default}
			
		}
		{\vspace{0.5em}\end{mdframed}\end{algorithmflt}
}

% And code boxes

\DeclareFloatingEnvironment[fileext=frm,placement={!ht},name=Code Listing]{codeflt}
\captionsetup[algorithmflt]{labelfont=bf}
\captionsetup[figure]{labelfont=bf}
\renewcommand{\theFancyVerbLine}{\rmfamily \textcolor[rgb]{0.7, 0.7, 0.7}{\arabic{FancyVerbLine}}}

\newenvironment{mycode}[4][]
{\VerbatimEnvironment
	\begin{codeflt}[tb]\begin{mdframed}
		\captionsetup{name=\faIcon{brackets-curly} \textbf{Code Listing}, singlelinecheck=false,font={color=id7-aubergine,sf},position=top}
		\vspace{0.5em}
		\caption{#3 \hfill #4}
		\vspace{0.5em}
		\captionsetup{style=default} 
	\begin{minted}[#1]{#2}}
	{\end{minted}\vspace{0.5em}\end{mdframed}\end{codeflt}}

\newenvironment{mycodefile}[5][]
{
	\begin{codeflt}[tb]\begin{mdframed}
			\captionsetup{name=\faIcon{brackets-curly} \textbf{Code Listing}, singlelinecheck=false,font={color=id7-aubergine,sf},position=top}
			\vspace{0.5em}
			\caption{#3 \hfill #4}
			\vspace{0.5em}
			\captionsetup{style=default} 
			\inputminted{#2}{#5}}
			{\vspace{0.5em}\end{mdframed}\end{codeflt}}
	
\usepackage[printwatermark]{xwatermark}
\newsavebox\mybox
\savebox\mybox{\tikz[color=id7-aubergine,opacity=0.3]\node{\sffamily DRAFT 1};}
%\newwatermark*[
%allpages,
%angle=45,
%scale=6,
%xpos=-20,
%ypos=15,
%]{\usebox\mybox}


% ======================

\begin{document}
  
\newgeometry{margin=0in}
\begin{titlepage}
    
    \tikz[remember picture,overlay] \node[opacity=1,inner sep=0pt] at (current page.center){\includegraphics[width=\paperwidth,height=\paperheight]{bg.eps}};
    \vspace{0.666\textheight} % height of the devil
    
    {\hspace{0pt}\vspace{0pt}\begin{tikzpicture}[scale=\paperwidth/1cm, overlay]
        \filldraw[draw=none,fill=white]
        (0, 0)
        -- (0.65838,0) 
        -- (0.71534285714,-0.1) 
        -- (0.7577,-0.0215)
        -- (0.8001, -0.1)
        -- (0.8571,0)
        -- (1, 0)
        -- (1, -0.45)
        -- (0, -0.45);
        
        \node[opacity=1,inner sep=0pt] at (0.7577, -0.15){\includegraphics[width=6cm]{logotype}};
        \node[text width=15cm] at (0.39,-0.15) {\warwickfont\fontsize{40}{10}\selectfont\textcolor{id7-aubergine}{Regular Expression\\\vspace{0.2cm}Refinement Types}};
        \end{tikzpicture}}
    
    {\par}
    \vspace{1.25cm}
    \vspace{3.5cm}
    {\hspace{0.75cm}\Huge \warwickfont Project Report}
    \vspace{0.16cm}
    {\par}
    {\hspace{0.75cm}\large \warwickfont Adam Williams (3\textsuperscript{rd} year Computer Science)}


    {\hspace{0.75cm}\large \warwickfont Michael Gale (supervisor)}
    \vfill
\end{titlepage}
\restoregeometry
\restorepagecolor

\pagebreak[5]
\newenvironment{abstract}{\centering{\normalfont\Large\sffamily\color{id7-aubergine}Abstract}\vspace{0.3cm}\\
	\hfill\begin{minipage}{0.95\textwidth}
		\rule{\textwidth}{1pt}}
	{\par\noindent\rule{\textwidth}{1pt}\end{minipage}}

\newenvironment{keywords}{\centering{\normalfont\Large\sffamily\color{id7-aubergine}Keywords}\vspace{0.3cm}\\
    \hfill\begin{minipage}{0.95\textwidth}
        \rule{\textwidth}{1pt}}
    {\par\noindent\rule{\textwidth}{1pt}\end{minipage}}

\tableofcontents
\pagebreak[5]
\begin{keywords}
    Type Systems, Refinement Types, Application Security, User Input, Satisfiability Modulo Theories, Programming Languages, Static Analysis
\end{keywords}

\vspace{0.5em}

\begin{abstract}
    Entire classes of modern web application vulnerabilities arise due to problematic user input handling. This includes cross-site scripting (XSS), \emph{injection} issues (SQL, LDAP, etc), insecure
    deserialisation and file inclusion vulnerabilities – all of which are encountered by information
    security firms on a regular basis in application assessments. This project explores the use of regular expressions as refinement types for constrained data in order to model user input validation. We
    formalise the type system of such a language and implement it. We then compare our system to and evaluate it against other, existing approaches by considering false positive and negative rates with a
    series of test cases. 
\end{abstract}



\chapter{Motivation}

Over the last decade, use of web and thick client applications globally has greatly increased. People increasingly access services online--to manage their finances \citep{jayawardhena2000changes}, use government services \citep{fox2010directgov} and communicate using social media \citep{boulianne2015social}. On a daily basis users entrust these systems with maintaining the privacy of their personal information and safeguarding their finances. With the transition from a web centred primarily around exchanging documents to a platform for deploying complex applications, security is increasingly important.

\section{Application Security}

Application security is of particular interest because it transcends the underlying infrastructure on which applications are deployed. Despite the popularity of cloud IaaS (infrastructure-as-a-service) and PaaS (platform-as-a-service) offerings which can substantially improve infrastructure security, applications will continue to be vulnerable.

The predominant cause of these vulnerabilities is improper user input handling \citep{schneier2011secrets}. The \emph{Open Web Application Security Project} (OWASP) regularly publishes a list of the top ten most critical security issues, and a subset of these are described below \citep{owasp10}:

\begin{description}
	\item[Injection] Covers query injection, where user input is improperly interpolated into a e.g. a database SQL query or a directory LDAP search. Malicious user input can retrieve or modify sensitive data, bypass authorisation controls and (in some cases) run arbitrary code \citep[p.~291]{stuttard2011web}.
	\item[Broken Authentication] Covers vulnerabilities such as insecure direct object access (IDOR) where authorisation checks are not implemented consistently and the user's request is trusted in one or more parts of the application \citep[p.~257]{stuttard2011web}.
	\item[XML External Entities (XXE)] A vulnerability which involves improperly handling user encoded in the XML interchange format. XML supports functionality to reference entities from an external location. Exploitation may allow arbitrary files to be read, sensitive data to be exposed or code to be executed  \citep[p.~384]{stuttard2011web}.
	\item[Cross-Site Scripting (XSS)] When user input is not properly handled in the context of a HTML web page or inside JavaScript, a user can provide malicious input that can run arbitrary code on the client. This can be used by an attacker to steal or misuse a victim's session \citep[p.~431]{stuttard2011web}.
	\item[Insecure Deserialization] Results from insecurely converting user input into a language object.
\end{description}

Many of these vulnerabilities--and the necessary techniques for preventing them--have been well-established for a number of years, and yet they continue to be regularly discovered in production applications \citep[p.~2]{schneier2011secrets}.

\section{Static Analysis}

Static analysis tools can detect some classes of vulnerability by examining source code. Within application security, static analysis tools are grouped under the \emph{Static Application Security Testing} SAST denomination in contrast to \emph{Dynamic Application Security Testing} (DAST) tools which operate at runtime and observe the behaviour of a running system. SAST tools work by either independently parsing the developer's code or analysing an \emph{abstract syntax tree} (AST) produced by the language toolchain\footnote{In the context of C\#, Microsoft have made the \emph{Roslyn} compiler source code available and many static analysis tools are built on top of this open platform.} and using a series of inspections to check and log common problems. Some more advanced tools use \emph{taint tracking} combined with information flow analysis to mark and track variables and parameters that have been influenced by user input \citep{denning1977certification}. A list of sinks that are deemed potentially dangerous (such as database query functions) is maintained, and user input flowing to any of these sinks results in an issue being logged.

As discussed in \citet{sadowski2018lessons}, it is preferable to detect issues in a static fashion--ideally integrated into the build process--to ensure that problems are actioned by developers. The false positive rate should also be minimised to avoid the risk of \emph{alert fatigue}, a problem which occurs in a variety of different contexts where the value of alerts is decreased due to a perception that often, there is no real substance to the warnings \citep{kesselheim2011clinical}.

If reliable and properly implemented, static analysis tooling has been shown to be able to prevent whole classes of bugs from making it into production \citep{sadowski2018lessons}.

\section{A Better Approach}

Existing static analysis are often unable to evaluate the effectiveness of input validation code that may already be in place--leading to false positives. This is because the tools consider code in isolation and cannot reason about the form of user input. Taint tracking is similarly binary, where data originates from user input and is assumed dangerous or originates elsewhere and assumed benign.

We describe a system which uses \emph{refinement types} in order to determine whether existing regular expression based input validation is effective. This happens at compile time, using an SMT solver to find situations where input could fail to be matched by a regular expression. This allows for potential security issues to be surfaced during type-checking.

\chapter{Background}
This chapter discusses the theory underpinning the techniques used in the implementation.


\section{Regular Expressions}
\label{regexbg}
Most programming languages include support for using \emph{regular expressions} to match strings. Formally, regular expressions are a means to specify a \emph{regular} language -- equivalent in power to the \emph{deterministic finite automaton} (DFA) and \emph{non-deterministic finite automaton} (NFA).



Some (or all) of the following operations are available to use when building a recognising a language using regular expressions:

\begin{description}
	\item[$R^*$ (Kleene-star)] Accept zero or more of the expression $R$.
	\item[$R^+$ (Kleene-plus)] Accept \emph{one} or more of the expression $R$. Equivalent to ${R^*}$.
	\item[$A \vert{} B$ (Alternation)] Permit expression $A$ \emph{or} $B$.
	\item[$AB$ (Concatenation)] Accept $A$ followed by $B$.
	\item[$R^C$ (Complement)] Accept the inverse/complement of the expression $R$.
\end{description}


We now consider an example regular language. In the UK, the first part of most postcodes matches the format of two letters followed by up to two numbers. For example, \texttt{CV8}, \texttt{CV4} or \texttt{SW1}. If we define the alphabet of uppercase letters $\Sigma_{A-Z} = \{A, B, C, \ldots, Z\}$ and digits $\Sigma_\mathcal{N} = \{0,1,2,3,4,5,6,7,8,9\}$ then we can formally describe a language $L(\Sigma_{A-Z} \Sigma_{A-Z}(\Sigma_\mathcal{N} | \Sigma_\mathcal{N} \Sigma_\mathcal{N})$.

As discussed, the syntax used in most programming languages differs somewhat and offers some convenience features for defining ranges of characters and specifying the desired number of occurrences of a particular expression:\\

\begin{minted}{csharp}
// Match: exactly two occurrences of a character in range A-Z
//        then at least one digit in 0-9 and optionally one more
string pattern = r"[A-Z]{2}[0-9][0-9]?";
var matchCollection = System.Text.RegularExpressions.Regex.Matches("CV31", pattern);
\end{minted}

Regular expressions are used extensively as an initial step when validating user input. For example, the popular web development framework \emph{ASP.NET MVC} natively allows developers to specify validation rules by way of a regular expression attribute. When user data is submitted in e.g. a form, the framework is able to automatically perform validation and reject input which does not match the expression.

\begin{mycodefile}{csharp}{Entity fields can be validated using regular expressions in ASP.NET MVC}{C\#}{codesample-csharp-regex.cs}
\end{mycodefile}

\subsection{DFAs and NFAs}
At their simplest, these automata are state machines which operate on a string by starting in an initial state and processing each character in turn. Depending on the character encountered, the automaton may \emph{transition} to a different state which can be marked as either an accepting or rejecting state. Once all characters are processed, the input string is said to belong to the language if the final state is accepting.

As described in \citet[p.~35]{sipser2012introduction}, we can formalise the definition of a DFA in terms of a 5-tuple $(Q, \Sigma, \delta, q_0, F)$ where the elements of the tuple are as follows:

\begin{description}
	\item[$Q$] The set of states in the automaton.
	\item[$\Sigma$] A set of characters known as the \emph{alphabet}.
	\item[$\delta$] Table of \emph{transitions} between states. Formally, it can be described as a function $\delta : Q \times \Sigma \rightarrow Q$ -- given a state from $Q$ which the automaton is in, receiving the character in $\Sigma$ will result in a new state from $Q$.
	\item[$q_0$] The initial state which the automaton starts in.
	\item[$F$] The set of accepting states.
\end{description}
	
\begin{figure}[H]
\begin{MyMdframed}
\vspace{0.5em}


\caption{\label{figure:dfa:1} A DFA, accepting the language \texttt{(aa)*}}
\vspace{0.5em}
\captionsetup{style=default}

\makebox[\linewidth][c]{\centering \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
	semithick]
	\node[initial,state,accepting]   (A)                      {$q_a$};
	\node[state]           (B)  [right of=A]  {$q_b$};
	
	\path (A) edge [bend left]             node {$a$} (B)
	(B) edge [bend left]              node {$a$} (A);
	\end{tikzpicture}}

\vspace{0.5em}

\end{MyMdframed}

\end{figure}

A simple DFA that accepts $2n$ occurrences of the character \texttt{a} is shown in figure \ref{figure:dfa:1}. We can define $M = (\{q_a,q_b\}, \{a\}, \delta, q_a, \{q_a\})$ and informally describe the transition function $\delta$ as mapping $(q_a, 'a') \rightarrow q_b$ and $(q_a, 'a') \rightarrow q_a$. The automaton alternates between states $q_a$ and $q_b$ every time a new character is processed -- whist the length is even, $q_a$ will be active and the string will be considered in the language.

Non-deterministic finite automata are equivalent in language recognition ability to the DFAs discussed above, but use a different processing model \citep[p.~46]{sipser2012introduction}. There is no requirement to account for every possible character from the alphabet $\Sigma$ and there is a new concept of an $\epsilon$-transition which can always be followed; such a transition is depicted by an edge labelled $\epsilon$ in automata diagrams. NFAs can be thought of as being able to process multiple ``paths'' in parallel. Figure \ref{figure:nfa:1} illustrates an NFA using $\epsilon$-transitions to capture \emph{alternation} between the languages $g^+$ and $f^+$ as defined at the beginning of section \ref{regexbg}.

We can formalise the definition of an NFA in terms of a 5-tuple $(Q, \Sigma, \delta, q_0, F)$ where the elements of the tuple are described below. Note that the transition function has changed.

\begin{description}
\item[$Q$] The set of states in the automaton.
\item[$\Sigma$] A set of characters known as the \emph{alphabet}.
\item[$\delta$] Table defining \emph{transitions} between states. Formally, it can be described as a function $\delta : Q \times \Sigma \cup \{\epsilon\} \rightarrow \mathcal{P}(Q)$ -- given a state from $Q$ which the automaton is in, receiving the character in $\Sigma$ will result in a set of possible new states, derived from the powerset (set of possible subsets) of $Q$.
\item[$q_0$] The initial state which the automaton starts in.
\item[$F$] The set of accepting states.
\end{description}

Not all languages are regular. For example, the matching parentheses language which accepts strings such as \texttt{(())} but not \texttt{(}, \texttt{))} or \texttt{((())} can be proven non-regular by contradiction (using the pumping lemma described in \citet{rabin1959finite}). As a result, no DFA, NFA or regular expression\footnote{The language \emph{can} however be recognised using a pushdown automata because it belongs to the set of deterministic context-free languages.} can encode the rules of this language.




\begin{figure}[H]
	\begin{MyMdframed}
	\vspace{0.5em}
 

\caption{\label{figure:nfa:1} An NFA, representing the language \texttt{g+|f+}}
\vspace{0.5em}
\captionsetup{style=default}

		\makebox[\linewidth][c]{\centering \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
		semithick]
		\node[initial,state]   (A)                      {$q_s$};
		\node[state]           (B)  [above right of=A]  {$q_a$};
		\node[state]           (B1) [right of=B]        {$q_{a1}$};
		\node[state]           (C)  [below right of=A]  {$q_b$};
		\node[state]           (C1) [right of=C]        {$q_{b1}$};
		\node[state,accepting] (F)  [below right of=B1] {$q_{f}$};
		
		\path (A) edge              node {$\epsilon$} (B)
		(A) edge              node {$\epsilon$} (C)
		(B) edge node {$g$} (B1)
		(B1) edge [bend left] node {$\epsilon$} (B)
		(B1) edge node {$\epsilon$} (F)
		(C) edge node {$f$} (C1)
		(C1) edge [bend left] node {$\epsilon$} (C)
		(C1) edge node {$\epsilon$} (F);
		\end{tikzpicture}}
		
\vspace{0.5em}

The initial state is $q_0$. As this automaton is non-deterministic, it can be viewed as ``branching'' and entering the two states $q_a$ and $q_b$ due to the $\epsilon$-transitions. $q_a$ is used for the \texttt{g+} component of the alternation in the original regular expression and, similarly, $q_b$ is used for the \texttt{f+} component. Both of these states require at least one occurrence of their respective character before entering the $q_{x1}$ state ($x in \{a, b\}$) -- the only way to proceed to the final accepting state $q_f$. 

\vspace{0.5em}

\end{MyMdframed}
\end{figure}

\subsection{Programming Language Support}

Most programming languages include a regular expression engine and offer syntax inspired by Perl's regular expressions. These ``regular'' expressions are often more powerful than the formal regular expressions discussed at the start of section \ref{regexbg} and can match non-regular languages.

For example, recall the balanced parentheses language. In PCRE (a library providing a regular expression engine inspired by Perl), the \texttt{(?n)} pattern can be used to recursively match using the n\textsuperscript{th} capture group. It is possible to then write an expression which will match balanced parentheses. Micosoft's .NET platform includes an extension to support \emph{balancing group definitions} which would also allow for balanced parentheses to be matched. Regular expressions using these language features and extensions are not \emph{regular} in the formal sense. Throughout this project, we only consider regular expressions according to their formal definition.

\section{SAT and SMT Solvers}

\subsection{Introducing SAT}

The SAT decision problem involves a propositional Boolean logic formula built from a number of variables and operations conjunction $\land$, disjunction $\lor$ and negation $\neg$. The question concerns whether the formula is \emph{satisfiable}--i.e. is there a set of \emph{valuations} for each of the variables which results in the overall formula evaluating to true?

If a formula \emph{cannot} be satisfied, there is no valuation for which the formula will evaluate to true. For example, the clauses may contradict each other as in $(a) \land (\neg a)$. The example below shows a satisfiable formula comprising 2 clauses and 3 variables:


\emph{Can the} \(
	(a \lor b \lor c) \land (\neg b \lor c)
\) \emph{propositional logic formula be satisfied?}\\

\textcolor{id7-emerald-green}{\textbf{Yes}}, set $a = T$, $b=F$, $c=T$. Then clause 1 evaluates to $(T \lor F \lor T) = T$ and clause 2 evaluates to $(\neg F \lor T) = T$. The whole formula evaluates to $T \land T = T$.

By exhaustive evaluation, we can prove a problem cannot be satisfied:

\emph{Can the} \(
    (a \lor b) \land (\neg a \lor b) \land (\neg b)
\) \emph{propositional logic formula be satisfied?}\\

\textcolor{id7-ruby-red}{\textbf{No}}, the clauses are contradictory. The table below shows exhaustively that no valuation of the variables result in the formula evaluating to true:

\arrayrulecolor{lightgrey} % <---
\def\arraystretch{1.5}%  1 is the default, change whatever you need
\begin{table}[H]
	\centering
	\rowcolors{1}{}{lightgrey}
	\begin{tabular}[t]{|p{0.05\linewidth}|p{0.05\linewidth}|p{0.1\linewidth}|}
		\hline
		\rowcolor{id7-aubergine}
		{\color[HTML]{FFFFFF} $\mathbf{a}$} & {\color[HTML]{FFFFFF} $\mathbf{b}$} & {\color[HTML]{FFFFFF} \sffamily  \textbf{Result}} \\ \hline
		$F$ & $F$ & $F$  \\ \hline
		$F$ & $T$ & $F$  \\ \hline
		$T$ & $F$ & $F$  \\ \hline
		$T$ & $T$ & $F$  \\ \hline
	\end{tabular}
	\caption{Enumerating all possible valuations for the variables $\{a, b\}$ used in the formula.}
	\label{table:landingredesign}
\end{table}

\subsubsection{Normal Forms}

Examples of formulae up to this point have been given in \emph{Conjunctive Normal Form} (CNF). That is, they are provided as a conjunction of disjunctive clauses. It is possible to convert any Boolean logic formula into this form. To \emph{evaluate} a given formula using a valuation of Boolean variables and values, we simply consider each clause in turn and enumerate the literals within each clause. Once any one literal has been found to be true, the disjunctive nature of the clauses allows us to ignore any remaining terms and move onto the next. Similarly we can skip all remaining clauses if one clause in a CNF formula is found to evaluate to $F$, since all clauses must be true.

To solve SAT, we could devise a naïve algorithm considering all possible assignments and evaluating the formula at each stage (as we did in the second example). Clearly such an approach would be inefficient--for Boolean variables with two possible assignment values, this algorithm would work in $\mathcal{O}(2^n)$.

As discussed in \citet{miltersen2005converting}, it is also possible to convert formulae to \emph{Disjunctive Normal Form} (DNF) using De Morgan's law. Using the formula from the original example, we can concert to DNF:

    \begin{description}
        \item[CNF] \(
        (a \lor b \lor c) \land (\neg b \lor c)
        \)
        \item[DNF] \(
        (a \land \neg b) \lor (c)
        \)
    \end{description}
    
    \spacedrule{}
    
    A more interesting example might comprise a formula of structure  \(
    (a \lor b) \land (c \lor d) \land (e \lor f)
    \), which is converted to the lengthy DNF formula below:
    
    \[
    (a \land c \land e) \lor (a \land c \land f) \lor (a \land d \land e) \lor (a \land d \land 
    f) \lor (b \land c \land e) \lor (b \land c \land f) \lor (b \land d \land e) \lor (b \land d \land
    f)
    \]
    \vspace{0.25em}

This is of some note, because SAT restricted to formulae in DNF can be solved in linear time using the procedure below:


\begin{outline}
	\1 For each clause in the formula, check each literal and keep a note of whether it is negated or not

	\2 If a clause contains the same literal and its negation, mark the clause as unsatisfiable.
	\2 Otherwise, the clause can be satisfied. The valuation for each literal is $F$ if they are negated, and $T$ otherwise.

	\1 If at least one clause is satisfiable, the entire problem is -- and we can stop processing.
	\1 If no clauses are satisfiable, the problem cannot be satisfied.
\end{outline}



However, as the second formula we converted illustrates, there can be an \emph{exponential increase} in size for an arbitrary propositional logic formula written in CNF. Hence, in the general case, we cannot use this conversion procedure to solve SAT in linear time for any Boolean logic formula.

\subsection{Cook-Levin and NP Completeness}

SAT is NP complete. It is computationally straightforward (i.e. possible in linear time) to check if a given valuation of variables is satisfying by evaluating the clauses within the entire formula. Furthermore, it has been shown that any problem in NP can be reduced to SAT by way of a nondeterministic Turing machine encoding \citep{Cook:1971:CTP:800157.805047} -- this is the statement of the Cook-Levin theorem.

This has an impact on the practical application of SAT solvers and the reliability of such applications. Whilst heuristics can be used to efficiently solve some SAT problems, there is no guarantee that a particular problem will be able to be solved in a reasonable timeframe. Generally though, if a solver returns SAT/UNSAT instead of timing out, it can be assumed that the result is correct with a good degree of confidence.


\subsection{Knuth's Algorithm A}

First discussed in \citet{Knuth:2015:ACP:2898950}, \citeauthor{Knuth:2015:ACP:2898950}'s \emph{Algorithm A} (also known as \textsc{SAT0}) solves SAT by backtracking. Designed as a basic solution to the problem of designing a SAT solver, it is an improvement on the naïve algorithm discussed earlier. For a SAT problem involving $n$ variables, the algorithm proceeds by setting the $n$\textsuperscript{th} variable to its ``most plausible'' value and then recursively doing the same for the $n-1$ previous variables. If at any point a contradiction is encountered, the value assigned to $n$ is flipped and the process repeats. For literals which are never negated in any clause, we can assume that they are true without issue. These are known as ``pure literals'', a concept which reappears in the DPLL algorithm discussed later.

At each stage, clauses must be modified to take into account the assignments, such as $x_1 = T$. This is achieved by removing any \emph{clause} which contains a literal $l = x_1$. For any clauses containing $l = \neg x_1$, this literal must be removed because it can no longer be used to satisfy the clause now that $x_1$ has been set. If $x_1$ is set to $F$, the same procedure happens in reverse (clauses containing $l = \neg x_1$ are removed, literals requiring $l = x_1$ are removed).
\label{algorithm:knuth:sat0}


\subsection{DPLL}

A more advanced approach than Knuth's SAT0 (discussed in section \ref{algorithm:knuth:sat0}) is the \emph{Davis–Putnam–Logemann–Loveland} (DPLL) algorithm. DPLL underpins a number of modern SAT solving software such as Microsoft's \emph{Z3} where it powers the core theory solver \citep{de2008z3}. The algorithm was developed by improving on the DP algorithm which was published in 1960 in \citet{Davis:1960:CPQ:321033.321034}.

For an arbitrary CNF SAT problem, the algorithm uses a process known as \emph{unitary resolution}. If all previous variables in a CNF clause are false, the disjunctive nature implies that the last literal \emph{must} be true. DPLL applies this process recursively. As briefly mentioned in algorithm \ref{algorithm:knuth:sat0}, DPLL also uses the concept of a ``pure literal'' which is defined as a literal for which its negation does not appear in the Boolean formula.

Two operations are used:

\begin{description}
	\item[\textsc{UnitPropagate}] If the clause contains \emph{one} unassigned literal, set the valuation for the variable in order to satisfy it.
	\item[\textsc{PureLiteralAssign}] Pure literals do not impact the search space, because they can always be satisfied with one truth value. This operation simplifies the clause using this fact.
\end{description}

The algorithm terminates in one of two cases \footnote{These DPLL termination conditions are taken verbatim from an encyclopedic description written previously by the author in \emph{Williams, A. (2019), `DPLL algorithm (section: algorithm termination)'}.}. Either the CNF formula $\phi$ is found to comprise a consistent set of literals -- that is, there is no $l$ and $\neg l$ for any literal l in the formula. If this is the case, the variables can be trivially satisfied by setting them to the respective polarity of the encompassing literal in the valuation. Otherwise, when the formula contains an empty clause, the clause is vacuously false because a disjunction requires at least one member that is true. In this case, the existence of such a clause implies that the formula (evaluated as a \emph{conjunction} of all clauses) therefore cannot evaluate to true and must be unsatisfiable.

\begin{algbox}{Davis-Putnam-Logemann-Loveland}
		DPLL's input is a set of clauses $\phi$ and the algorithm returns a Boolean value representing whether the problem is satisfiable or not. The algorithm proceeds as follows:
		
\begin{algorithmic}
\Function{DPLL}{$\phi$}
	\If{\Call{IsConsistent}{$\phi$}} \Comment Clauses contain no $x_1$ and $\neg x_1$
		\State ${\bf return}~\textsc{true}$ \Comment We were able to find a satisfying valuation
	\EndIf
	
	\If{\Call{HasEmpty}{$\phi$}} \Comment At least one clause in the formula is empty/unsatisfiable
		\State ${\bf return}~\textsc{false}$
	\EndIf
	
	\For{unit clause $\{l\} \in \phi$} \Comment Unit clauses containing one unassigned literal
		\State $\phi = $ \Call{UnitPropagate}{$l, ~ \phi$} \Comment Apply unit propagation operation
	\EndFor
	
	\For{pure literal $l \in \phi$} \Comment Pure literals are never negated
		\State $\phi = $ \Call{PureLiteralAssign}{$l, ~ \phi$} \Comment Delete pure literals, these do not impact search 
	\EndFor
	
    \State $l = $ \Call{PickLiteral}{$\phi$} \Comment Arbitrarily pick an unassigned literal 
    
   
	\State ${\bf return}$~\Call{DPLL}{$\phi[T/l]$}~${\bf or}$~\Call{DPLL}{$\phi[F/l]$}  \Comment Try literal set to true, short circuit success, otherwise try false

\EndFunction
\end{algorithmic}	
\vspace{0.5em}
	
	\label{algorithm:sat:dpll}
\end{algbox}


Consider the following problem adapted from \citep{presdpllt}:


\begin{center}
\emph{Is the propositional logic formula below satisfiable?}

\(
    (A \lor B) \land (C \lor D) \land \neg B
\)

\end{center}


\begin{enumerate}
    \item We first check if the formula $\phi$ is consistent. There should be no $x_1$ and $\neg x_1$ within the formula if this is the case. $B$ violates this property, so the formula is not yet consistent.
    \item We proceed to check if any clauses are empty which would indicate an unsatisfiable problem. This is not the case, there are no empty clauses.
    \item The unit clauses in the formula at this stage are $\{\neg B\}$. We apply the unit propagation rule and adjust clause $(A \lor B)$.
\end{enumerate}

\begin{center}
\setlength{\fboxsep}{2pt}
\(
(A \lor \)\colorbox{id7-aubergine}{$ \textcolor{white}{B}$}\() \land (C \lor D) \land \neg B\)

\emph{unit propagation}

\(A ~\land (C \lor D) \land \neg B\)

\end{center}

\begin{enumerate}
      \setcounter{enumi}{3}
      \item We now look for all pure literals. Recall that a pure literal is one that is never negated elsewhere in the formula. The first pure literal we consider is $A$. It appears as $A$ on its own in the formula, so we assign it a value of $T$.
\end{enumerate}

\begin{center}
    \setlength{\fboxsep}{2pt}
    \(
    (\)\colorbox{id7-aubergine}{$ \textcolor{white}{T}$}\() \land (C \lor D) \land \neg B\)
    
    \emph{simplify}
    
    \((C \lor D) \land \neg B\)
\end{center}


\begin{enumerate}
\setcounter{enumi}{4}
\item We repeat for $\neg B$, $C$ and $D$ .
\end{enumerate}

\begin{center}
    \setlength{\fboxsep}{2pt}
    
    \((C \lor D) \land \neg ~ \)\colorbox{id7-aubergine}{$ \textcolor{white}{F}$}
    
    \emph{simplify}
    
    \((C \lor D) \land \)\colorbox{id7-aubergine}{$ \textcolor{white}{T}$}
        
    \emph{simplify}
    
    \((C \lor D)\)
    
    \emph{pure literal $C$}
    
    \((\)\colorbox{id7-aubergine}{$ \textcolor{white}{T}$}\( \lor D)\)
        
    \emph{simplify}
    
    \(D\)
    
    \emph{pure literal $D$}
    
    \colorbox{id7-aubergine}{$ \textcolor{white}{T}$}
\end{center}

\begin{enumerate}
    \setcounter{enumi}{5}
    \item No unassigned literals remain. The satisfying valuation is $A=T, B=F, C=T, D=T$.
\end{enumerate}

\subsection{Satisfiability Modulo Theories (SMT)}

\begin{mycodefile}{python}{\label{code:z3:1}Solving a simple multivariate equation with Z3}{Python}{multivariate.py}
	
	Using the Python bindings for Z3, we solve the equation $y^2 + x^2 = 20$ for integer $x$ and $y$. When executed, the solver yields the valuation $x = 2,~y = 4$.
	

	\vspace{0.5em}
\end{mycodefile}

Thus far, we have only considered solving problems involving Boolean variables and their negation. With SMT, we extend the problem to satisfiability of arbitrary first-order logic theories. This is more flexible and reduces the need for encoding work to formulate problems in terms of CNF formulae. With an SMT solver, such as Z3, we can solve systems of equations as shown in code listing \ref{code:z3:1}.

We define a theory $T$ as a tuple $(\Sigma_T, I_T)$ where $\Sigma_T$ is the alphabet/list of function symbols within the theory $T$ and $I_T$ defines the \emph{interpretations} or meaning in the theory. For example, consider the theory defining less-than and greater-than on positive integer numbers:

\(
T = (\{0,1,2,3,4,5,6,7,8,9,<,>,x,y\}, I_T)
\)

Then $x < 4$ for $x = 2$ is $T$ under $I_T$.

Using CNF as before, a simple problem under this theory could require the clauses $(x > y \lor x < 10) \land (y < 5) \land (4 > x)$ to be satisfied. Most SMT solvers would then provide a \emph{model}, assigning possible satisfying values to the variables in the problem. In this example, $x = 4,~y=4$ would suffice.


\subsection{DPLL(T): Extending DPLL to Arbitrary Theories}

First described in \citet{ganzinger2004dpll} and presented in \citet{presdpllt}, DPLL(T) extends the power of DPLL to a theory $T$ (as defined above) using a repeated two-phase approach:

\begin{itemize}
	\item First, all functions under the theory $T$ in the problem are replaced with a Boolean variable. DPLL then proceeds as described earlier to find a satisfying valuation for the Boolean variables.
	\item Once a full set of valuations are available, a specialised \emph{theory solver} attempts to determine if the valuations can be satisfied under the theory $T$. If these valuations yield logical constraints that are contradictory, the original formula $\phi$ is augmented with an additional clause to reflect the requirement that the two constraints cannot both be true.
	\item If the formula has been modified as the result of a contradiction, the SAT solver is executed again to retrieve a new valuation -- assuming it is possible to backtrack.
	\item If at any stage it is not possible to backtrack and the functions required to be true contradict each other, the entire problem is unsatisfiable.
\end{itemize}

In DPLL(T), the theory solver is queried as an oracle and used each time the SAT solver has found a valuation. Although we have discussed theories relating to linear integer inequalities, this approach is equally applicable to other theories. Z3str3, which powers string solving in Z3, is built on this principle and uses a theory solver that is equipped with knowledge of non-deterministic finite automata \citep{berzish2017z3str3}.

\section{Refinement Types}

Within type systems, refinement types allow for predicate-based constraints to be applied to types in order to restrict the domain of elements which belong to the type.

\citet{benjaminpierce2002} describes them as ``a restricted form of intersection types'' that ``preserve type inference and allow more errors to be detected at compile time''.

A local variable used to store natural numbers could be constrained via a refinement type such as $\{n: \mathbb{N}\ \mid n \leq 3\}$; only $\{0, 1, 2, 3\}$ would then be permitted for values of $n$ under this constraint. Equally, this type can be applied to strings. A length constraint could be written as $\{s : \Sigma^* \mid \left| s \right| = 4 \}$.

In order to model common input validation practice, we allow regular expression membership to be expressed using refinement types. For example, $\{s: \Sigma^* \mid s \in L(ba+)\}$ would allow \texttt{"baa"} to be assigned as a value of some variable $s$, but not \texttt{"a"}. This refinement type can then be applied to local variables as well as function return types and parameter types.

\chapter{Prior Art}

There is a wealth of existing work within the areas of static analysis and program verification. This chapter aims to explore, and evaluate, some of the these works.

\section{Program Verification}

\subsection{Dafny}

Dafny is a language designed by Microsoft Research with built-in static verification functionality and modern programming language features (including polymorphic types). The language itself is imperative and allows programmers to specify functions with pre and post-conditions which are verified at compile time \citep{dafny2}. Recent versions of Dafny allow programs to be compiled into executables targetting the .NET framework \citet{dafny}.

\begin{mycodefile}{dafnylex.py:DafnyLexer -x}{\label{code:dafny:1}Factorial function and a pre-condition violation}{Dafny}{factorial.dfy}
	
	In this sample, we define a function called \texttt{Fac} which calculates the factorial of a given input integer $n$. For example, \texttt{Fac(3)} yields $3 \times 2 \times 1 = 6$. Using the \texttt{requires} keyword, we specify a pre-condition on the function to ensure that any argument must satisfy $n \ge 1$. The \texttt{Main} function then calls \texttt{Fac} with a negative number, which causes a verification error at compile time.

	\vspace{0.5em}
\end{mycodefile}

The language uses an intermediate representation language known as \emph{Boogie} which is able to derive constraints. These constraints are passed to the Z3 SMT solver to verify the user's program. Listing \ref{code:dafny:1} shows an example Dafny program which causes a compile-time verification error.

Dafny has some limited string support. An example is shown in listing \ref{code:dafny:2} with a function pre-condition on the length of a string. Strings in Dafny are treated as equivalent to the type \texttt{seq<char>} (that is, a sequence of characters) so although it is possible to retrieve e.g. the length of such a sequence, there is no built-in regular expression support. Whilst it \emph{is} possible to write a helper function and call it from within a pre-condition or post-condition, it then becomes necessary to manually implement the regular expression check in imperative code (as in listing \ref{code:dafny:3})

\begin{mycodefile}{dafnylex.py:DafnyLexer -x}{\label{code:dafny:2}Factorial function and a pre-condition violation}{Dafny}{factorial.dfy}
	
	In this sample, we define a function called \texttt{Fac} which calculates the factorial of a given input integer $n$. For example, \texttt{Fac(3)} yields $3 \times 2 \times 1 = 6$. Using the \texttt{requires} keyword, we specify a pre-condition on the function to ensure that any argument must satisfy $n \ge 1$. The \texttt{Main} function then calls \texttt{Fac} with a negative number, which causes a verification error at compile time.

	\vspace{0.5em}
\end{mycodefile}

\begin{mycodefile}{dafnylex.py:DafnyLexer -x}{\label{code:dafny:3}Manually implementing a regular expression pre-condition}{Dafny}{regex.dfy}
	
	It should be immediately apparent how much more verbose this approach is than a refinement type. For more complex regular expressions, it becomes difficult to manually implement the DFA/NFA required to check the string which increases the likelihood of implementation bugs in the verification part of the program. This should be avoided at all costs, since it can cause false confidence in the correctness of the code.

	\vspace{0.5em}
\end{mycodefile}


There is some limited interoperability support with other .NET code \citep{wilcowio}, but the absence of a standard library or input/output support limits Dafny's potential to an existence as an interesting research language.

\subsection{Liquid Haskell}

Liquid Haskell is a program verifier for Haskell. Refinement types are supported in the form of special nested comments which specify \emph{liquid types}.

The logic available for use in these type specifications is limited to ensure that the derived \emph{verifiable conditions} that are eventually passed to the SMT solver are \emph{decidable}. Thus, whilst Liquid Haskell supports basic logical expressions, relations and operators, there is no support for regular expression membership checks or arbitrary code execution to implement such functionality.

Listing \ref{code:liquidhaskell:1} shows an example of a type constrained using Liquid Haskell to only permit odd integer members.

\begin{mycodefile}{haskell}{\label{code:liquidhaskell:1}An \texttt{Odd} type to model odd numbers}{Haskell}{odds.hs}
	
	A violation is triggered by \texttt{oddNumberThatIsActuallyEven} which, although a member of the \texttt{Odd} data type, has been assigned a value of 8.
	\vspace{0.5em}
\end{mycodefile}

\section{Static Analysis and Security Tooling}

\subsection{Roslyn Security Guard}

\todobox{Not actively maintained, but includes some interesting inspections to talk about. Generally rather limited, unable to tell if validation has happened, can only recognise hardcoded method names.}

\subsection{Snyk}

\begin{mycodefile}{groovy}{\label{code:gradle:1}Specifying dependencies using a build tool}{Gradle}{build.gradle}

\end{mycodefile}

Snyk is a polyglot tool which analyses system dependencies to find components with known security vulnerabilities. Build files which specify dependencies (example in listing \ref{code:gradle:1}) are parsed and analysed.

\chapter{Design and Implementation}

\todobox{Language design (syntax), architecture of type checker and interpreter, libraries used (Z3, ANTLR4, introductions to both with code samples), Gradle plugin, syntax highlighting with WASM}


\begin{mycodefile}{rrtlex.py:RrtLexer -x}{\label{code:rrt:1}A factorial function written in the RRT language}{RRT}{factorial.rrt}
	\vspace{0.5em}
\end{mycodefile}

\chapter{Testing}

\todobox{Unit testing, manual testing (boundary conditions, adversarial input), integration testing (lexer, parser, interpreter)}

\chapter{Evaluation and Conclusions}

\todobox{This needs to be completed by evaluating not just the performance of the tool against existing static analysis software, but also the scheduling of the project and project management.}

\chapter{Future Work}
\todobox{Flesh this out:\begin{itemize}
		\item Non-regular ``regular expressions'' like we see in PHP, Perl etc
		\item Integration with languages such as C\#--take advantage of Roslyn? Scala/Java could also work by using annotations.
		\item Extend Dafny/Haskell to take advantage of Z3str3?
		\item Or, continue working on the proof of concept language to make it more palatable for serious use (more types, generics, .. objects)
\end{itemize}}


\titleformat{\chapter}[display]
{\normalfont \sffamily \Huge  \color{id7-aubergine}}
{}{0pt}{}[]

\bibliographystyle{agsm}
\bibliography{bibliography}

\end{document}
